{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_g16_all = []\n",
    "for i in range(33):\n",
    "    i1 = (\"%06d\" % (i+1))\n",
    "    i1 = str(i1)\n",
    "    mols_g16_all.append(i1+'.log')\n",
    "b3lyp = [] \n",
    "blyp = []\n",
    "cam_b3lyp = []\n",
    "lc_blyp = []\n",
    "lc_whpbe = [] \n",
    "m062x = [] \n",
    "m11 = [] \n",
    "pbe1pbe = [] \n",
    "pbepbe = [] \n",
    "pw91pw91 = [] \n",
    "svwn5 = [] \n",
    "tpssh = [] \n",
    "tpsstpss = []\n",
    "wb97xd = [] \n",
    "functionals_list = [b3lyp, blyp, cam_b3lyp, lc_blyp, lc_whpbe, m062x, m11, pbe1pbe, pbepbe, pw91pw91, svwn5, tpssh,\n",
    "                   tpsstpss, wb97xd]\n",
    "f_list = ['b3lyp', 'blyp', 'cam_b3lyp', 'lc_blyp', 'lc_whpbe', 'm062x', 'm11', 'pbe1pbe', 'pbepbe', 'pw91pw91', \n",
    "          'svwn5', 'tpssh', 'tpsstpss', 'wb97xd']\n",
    "def listtostring(s1):\n",
    "    str1 = \"\"\n",
    "    for ele in s1:\n",
    "        str1 += ele\n",
    "    return str1\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "for i in range(len(functionals_list)):\n",
    "    for j in range(len(mols_g16_all)):\n",
    "        s = namestr(functionals_list[i], globals())\n",
    "        t = listtostring(s)\n",
    "        functionals_list[i].append('../33_benchmark/'+t+'/'+mols_g16_all[j])\n",
    "steomccsd = []\n",
    "dlpnosteomccsd = []\n",
    "composite_list = [steomccsd, dlpnosteomccsd]\n",
    "mols_orca_all = []\n",
    "for i in range(33):\n",
    "    i1 = (\"%06d\" % (i+1))\n",
    "    i1 = str(i1)\n",
    "    mols_orca_all.append(i1+'.out')\n",
    "for i in range(len(composite_list)):\n",
    "    for j in range(len(mols_orca_all)):\n",
    "        s = namestr(composite_list[i], globals())\n",
    "        t = listtostring(s)\n",
    "        composite_list[i].append('../33_benchmark/'+t+'/'+mols_orca_all[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "functionals_list_v = [blyp, pbepbe, pw91pw91, svwn5, tpsstpss]\n",
    "for i in range(len(functionals_list_v)):\n",
    "    functionals_list_v[i].pop(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining requied functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pattern='Normal termination of Gaussian 16'\n",
    "E1_pattern='Excited State   1:'\n",
    "E2_pattern='Excited State   2:'\n",
    "p1 = 4\n",
    "p2 = 8\n",
    "def extract_E12_f12_g16(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    iline=0\n",
    "    for line in file:\n",
    "        if re.search(comp_pattern, line):\n",
    "            iline=iline+1\n",
    "    if (iline < 1):\n",
    "        print('ERROR: Can\\'t find <',comp_pattern,'> in ',filename)\n",
    "        file.close()\n",
    "    elif (iline==1):\n",
    "        file.close()\n",
    "        file = open(filename, \"r\")\n",
    "        mark_e1 = 0\n",
    "        for l1 in file:\n",
    "            if re.search(E1_pattern, l1):\n",
    "                mark_e1 = l1\n",
    "        file.close()\n",
    "        file = open(filename, \"r\")\n",
    "        mark_e2 = 0\n",
    "        for l2 in file:\n",
    "            if re.search(E2_pattern, l2):\n",
    "                mark_e2 = l2\n",
    "        file.close()        \n",
    "    E1 = float( mark_e1.split()[p1] ) \n",
    "    f0 = str( mark_e1.split()[p2] ) \n",
    "    fx = float(re.sub(\"[^0123456789\\.]\", '', f0))\n",
    "    f1 = float(\"{:.6f}\".format(fx))\n",
    "    E2 = float( mark_e2.split()[p1] ) \n",
    "    f0 = str( mark_e2.split()[p2] ) \n",
    "    fx = float(re.sub(\"[^0123456789\\.]\", '', f0))\n",
    "    f2 = float(\"{:.6f}\".format(fx))\n",
    "    return E1, f1, E2, f2\n",
    "p1_orca = 2\n",
    "p2_orca = 3\n",
    "comp_pattern_orca='ORCA TERMINATED NORMALLY'\n",
    "Pattern_orca_1='UNRELAXED EXCITED STATE DIPOLE MOMENTS'\n",
    "Pattern_orca_2='ABSORPTION SPECTRUM VIA TRANSITION ELECTRIC DIPOLE MOMENTS'\n",
    "def extract_E12_f12_orca(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    iline=0\n",
    "    for line in file:\n",
    "        if re.search(comp_pattern_orca, line):\n",
    "            iline=iline+1\n",
    "    if (iline < 1):\n",
    "        print('ERROR: Can\\'t find <',comp_pattern_orca,'> in ',filename)\n",
    "        file.close()\n",
    "    elif (iline==1):\n",
    "        file.close()\n",
    "        file = open(filename, \"r\")\n",
    "        line_number = 0\n",
    "        m1 = 0\n",
    "        m2 = 0\n",
    "        for l1 in file:\n",
    "            line_number += 1\n",
    "            if re.search(Pattern_orca_1, l1):\n",
    "                m1 = line_number + 4\n",
    "                m2 = line_number + 5\n",
    "        file.close()\n",
    "        file = open(filename, \"r\")\n",
    "        line_number = 0\n",
    "        mark_e1 = 0\n",
    "        mark_e2 = 0\n",
    "        for l1 in file:\n",
    "            line_number += 1\n",
    "            if line_number == m1:\n",
    "                mark_e1 = l1\n",
    "            if line_number == m2:\n",
    "                mark_e2 = l1\n",
    "        file.close()\n",
    "        \n",
    "        file = open(filename, \"r\")\n",
    "        line_number = 0\n",
    "        m3 = 0\n",
    "        m4 = 0\n",
    "        for l1 in file:\n",
    "            line_number += 1\n",
    "            if re.search(Pattern_orca_2, l1):\n",
    "                m3 = line_number + 5\n",
    "                m4 = line_number + 6\n",
    "        file.close()\n",
    "        file = open(filename, \"r\")\n",
    "        line_number = 0\n",
    "        mark_e3 = 0\n",
    "        mark_e4 = 0\n",
    "        for l1 in file:\n",
    "            line_number += 1\n",
    "            if line_number == m3:\n",
    "                mark_e3 = l1\n",
    "            if line_number == m4:\n",
    "                mark_e4 = l1\n",
    "        file.close()       \n",
    "    E1 = float( mark_e1.split()[p1_orca] ) \n",
    "    f1 = float( mark_e3.split()[p2_orca] )\n",
    "    E2 = float( mark_e2.split()[p1_orca] ) \n",
    "    f2 = float( mark_e4.split()[p2_orca] ) \n",
    "    return E1, f1, E2, f2\n",
    "\n",
    "def make_csv(filename,Nrows,Ncols,Header,Values):\n",
    "    file = open(filename, \"w\")\n",
    "    for icol in range(Ncols):\n",
    "        if icol == Ncols-1:\n",
    "            file.write(Header[icol]+'\\n')\n",
    "        else:\n",
    "            file.write(Header[icol]+',')\n",
    "    for irow in range(Nrows):\n",
    "        for icol in range(Ncols):\n",
    "            if icol == Ncols-1:\n",
    "                file.write(str(Values[icol][irow])+'\\n')\n",
    "            else:\n",
    "                file.write(str(Values[icol][irow])+',')\n",
    "    file.close()   \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "H1 = ['title', 'E1', 'f1', 'E2', 'f2']\n",
    "for i in range(len(functionals_list)):\n",
    "    V = np.zeros([5,len(functionals_list[i])])\n",
    "    for imol in range(len(functionals_list[i])):\n",
    "        mol = functionals_list[i][imol]\n",
    "        E1, f1, E2, f2 =extract_E12_f12_g16(mol)\n",
    "        V[0,imol] = imol + 1\n",
    "        V[1,imol] = E1\n",
    "        V[2,imol] = f1\n",
    "        V[3,imol] = E2\n",
    "        V[4,imol] = f2\n",
    "        s = namestr(functionals_list[i], globals())\n",
    "        t = listtostring(s)\n",
    "    tmp = make_csv('../csv_files/'+t+'.csv',len(functionals_list[i]),len(H1),H1,V)\n",
    "for i in range(len(composite_list)):\n",
    "    V = np.zeros([5,len(composite_list[i])])\n",
    "    for imol in range(len(composite_list[i])):\n",
    "        mol = composite_list[i][imol]\n",
    "        E1, f1, E2, f2 =extract_E12_f12_orca(mol)\n",
    "        V[0,imol] = imol + 1\n",
    "        V[1,imol] = E1\n",
    "        V[2,imol] = f1\n",
    "        V[3,imol] = E2\n",
    "        V[4,imol] = f2\n",
    "        s = namestr(composite_list[i], globals())\n",
    "        t = listtostring(s)\n",
    "    tmp = make_csv('../csv_files/'+t+'.csv',len(composite_list[i]),len(H1),H1,V)\n",
    "composite_list_v = [steomccsd, dlpnosteomccsd]\n",
    "for i in range(len(composite_list_v)):\n",
    "    composite_list_v[i].pop(11)\n",
    "for i in range(len(composite_list_v)):\n",
    "    V = np.zeros([5,len(composite_list_v[i])])\n",
    "    for imol in range(len(composite_list_v[i])):\n",
    "        mol = composite_list_v[i][imol]\n",
    "        E1, f1, E2, f2 =extract_E12_f12_orca(mol)\n",
    "        V[0,imol] = imol + 1\n",
    "        V[1,imol] = E1\n",
    "        V[2,imol] = f1\n",
    "        V[3,imol] = E2\n",
    "        V[4,imol] = f2\n",
    "        s = namestr(composite_list_v[i], globals())\n",
    "        t = listtostring(s)\n",
    "    tmp = make_csv('../csv_files/'+t+'_v.csv',len(composite_list_v[i]),len(H1),H1,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1515454545454545, 0.0976666666666665, 0.002158384969696969, 0.018499701848484852)\n",
      "('b3lyp', 0.28392121212121224, 0.30208484848484835, 0.0059421812121212125, 0.014287678878787876)\n",
      "('blyp', 0.6459281249999999, 0.7483, 0.0062494673125000014, 0.04852411971875)\n",
      "('cam_b3lyp', 0.2981121212121211, 0.3828696969696968, 0.0048769424848484864, 0.015282904575757572)\n",
      "('lc_blyp', 0.5059848484848484, 0.6920666666666666, 0.03439633103030304, 0.04377129409090909)\n",
      "('lc_whpbe', 0.5468575757575759, 0.7320212121212121, 0.03364985606060607, 0.04739105221212121)\n",
      "('m062x', 0.42756969696969677, 0.43762424242424225, 0.006487880484848484, 0.014536049424242425)\n",
      "('m11', 0.3824212121212121, 0.33744242424242404, 0.005946306, 0.021342249909090904)\n",
      "('pbe1pbe', 0.2857090909090909, 0.3016818181818181, 0.006034810121212122, 0.01694003281818181)\n",
      "('pbepbe', 0.5431625, 0.635046875, 0.0063621038125, 0.04618736653125)\n",
      "('pw91pw91', 0.62105, 0.7250531249999999, 0.0065611134375, 0.047877244718749996)\n",
      "('svwn5', 0.5263937500000001, 0.5893343749999999, 0.0083534158125, 0.026844187656249997)\n",
      "('tpssh', 0.2699515151515153, 0.2899999999999998, 0.004909739939393938, 0.01573540027272727)\n",
      "('tpsstpss', 0.3553718750000002, 0.4242593749999999, 0.0059052211875, 0.015085543781249997)\n",
      "('wb97xd', 0.41058181818181805, 0.5370272727272727, 0.014555314787878786, 0.026069560939393933)\n"
     ]
    }
   ],
   "source": [
    "ref = pd.read_csv('../csv_files/steomccsd.csv',header=0)\n",
    "ref_v = pd.read_csv('../csv_files/steomccsd_v.csv',header=0)\n",
    "dlpno = pd.read_csv('../csv_files/dlpnosteomccsd.csv',header=0)\n",
    "diff_dlpno_E1 = abs(dlpno.E1[:] - ref.E1[:])\n",
    "diff_dlpno_E2 = abs(dlpno.E2[:] - ref.E2[:])\n",
    "diff_dlpno_f1 = abs(dlpno.f1[:] - ref.f1[:])\n",
    "diff_dlpno_f2 = abs(dlpno.f2[:] - ref.f2[:])\n",
    "print(np.mean(diff_dlpno_E1),np.mean(diff_dlpno_E2),np.mean(diff_dlpno_f1),np.mean(diff_dlpno_f2))\n",
    "for i in range(len(functionals_list)):\n",
    "    if (len(functionals_list[i])) == 33:\n",
    "        #print(functionals_list[i])\n",
    "        s = namestr(functionals_list[i], globals())\n",
    "        t = listtostring(s)\n",
    "        x = t+'_pd'\n",
    "        x = pd.read_csv('../csv_files/'+t+'.csv',header=0)\n",
    "        diff_E1 = abs(x.E1[:] - ref.E1[:])\n",
    "        diff_E2 = abs(x.E2[:] - ref.E2[:])\n",
    "        diff_f1 = abs(x.f1[:] - ref.f1[:])\n",
    "        diff_f2 = abs(x.f2[:] - ref.f2[:])\n",
    "    elif (len(functionals_list[i])) == 32:\n",
    "        #print(functionals_list[i])\n",
    "        s = namestr(functionals_list[i], globals())\n",
    "        t = listtostring(s)\n",
    "        x = t+'_pd'\n",
    "        x = pd.read_csv('../csv_files/'+t+'.csv',header=0)\n",
    "        diff_E1 = abs(x.E1[:] - ref_v.E1[:])\n",
    "        diff_E2 = abs(x.E2[:] - ref_v.E2[:])\n",
    "        diff_f1 = abs(x.f1[:] - ref_v.f1[:])\n",
    "        diff_f2 = abs(x.f2[:] - ref_v.f2[:])\n",
    "    print(f_list[i],np.mean(diff_E1),np.mean(diff_E2),np.mean(diff_f1),np.mean(diff_f2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
